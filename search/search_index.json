{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#who-we-are","title":"Who we are","text":"<p>Transformationflow O\u00dc is a Google Cloud Partner, headquartered in Estonia (EU). </p> <p>We are a remote, specialist team of Google Cloud Certified Professional Data Engineers who build data automation solutions and libraries on Google Cloud.  We have been working exclusively with Google Cloud and BigQuery since 2017.</p>"},{"location":"#what-we-do","title":"What we do","text":"<p>We design, build, manage and license serverless Google Cloud data automation solutions and libraries.</p>"},{"location":"#how-we-do-it","title":"How we do it","text":"<p>We use BigQuery as a foundation, in addition to complementary Google Cloud products such as:</p> <ul> <li>Google Cloud Storage for file ingestion, storage and backup</li> <li>Pub/Sub for streaming data, messaging and scheduled query monitoring</li> <li>Python Cloud Functions for custom actions, notifications and interaction with external APIs</li> <li>Remote Functions to deploy Cloud Functions in BigQuery workflows</li> <li>Scheduled Queries for automation and orchestration</li> <li>BigQuery ML for AI/ML and generative AI workflows</li> <li>Looker Studio for end-user and data monitoring dashboards</li> </ul> <p>We have advanced capabilities in all aspects of GoogleSQL and the GoogleSQL procedural language.  We use these capabilities to build functions, procedures and table functions which solve complex data automation challenges in a rapid, scalable and replicable manner.</p>"},{"location":"libraries/","title":"Libraries","text":""},{"location":"libraries/#bigquery-tools","title":"BigQuery Tools","text":"<p>The <code>bqtools</code> library contains the low-level building blocks used to build, deploy and manage data automation solutions and products. It enables functional engineering within the native BigQuery environment.</p> <p>The <code>decodedata</code> libraries is based on the <code>bqtools</code> foundations.</p> <p>BigQuery Tools </p>"},{"location":"libraries/#decode-data-for-ga4","title":"Decode Data for GA4","text":"<p>The <code>decodedata</code> library automates custom remodelling of GA4 data in BigQuery, simplifying the structure and optimising performance.</p> <p>It also enables integration of multiple GA4 properties and is available to licensed customers.</p> <p>Decode Data for GA4 </p>"},{"location":"signup/","title":"","text":""},{"location":"signup/#plans","title":"Plans","text":""},{"location":"signup/#installation","title":"Installation","text":""},{"location":"publications/medium/","title":"Medium","text":"<ul> <li> <p> June 21, 2024  11 min read </p> </li> <li> <p> June 14, 2024  17 min read </p> </li> <li> <p> June 5, 2024  16 min read </p> </li> <li> <p> March 27, 2024  5 min read </p> </li> <li> <p> Sep 21, 2023  8 min read </p> </li> <li> <p> May 25, 2022   5 min read </p> </li> <li> <p> Apr 22, 2021   6 min read </p> </li> <li> <p> Aug 5, 2022   9 min read </p> </li> <li> <p> Mar 15, 2022   9 min read </p> </li> <li> <p> Jan 3, 2022   7 min read </p> </li> <li> <p> Nov 10, 2021   4 min read </p> </li> <li> <p> Apr 27, 2021   3 min read </p> </li> </ul>"},{"location":"publications/medium/#understanding-the-ga4-bigquery-export-schema-and-structure","title":"Understanding the GA4 BigQuery Export Schema and Structure","text":""},{"location":"publications/medium/#_1","title":"Medium","text":"<p>A qualitative investigation into one of the weirdest data structures ever forced upon millions of innocent, unsuspecting analysts</p> <p> Continue reading</p>"},{"location":"publications/medium/#a-guide-to-functional-data-engineering-in-bigquery","title":"A Guide to Functional Data Engineering in BigQuery","text":""},{"location":"publications/medium/#_2","title":"Medium","text":"<p>An exploration of the Functional Data Engineering paradigm and how to implement this in BigQuery</p> <p> Continue reading</p>"},{"location":"publications/medium/#how-to-build-a-simple-data-stack-on-bigquery","title":"How to Build a Simple Data Stack on BigQuery","text":""},{"location":"publications/medium/#_3","title":"Medium","text":"<p>Building data infrastructure on BigQuery is a highly capable, escalable, extensible, accessible and future-proof choice for any team or organisation, at any scale</p> <p> Continue reading</p>"},{"location":"publications/medium/#essential-sql-functions-for-ga4-bigquery-export-analysis","title":"Essential SQL Functions for GA4 BigQuery Export Analysis","text":""},{"location":"publications/medium/#_4","title":"Medium","text":"<p>The fundamental functions you\u2019ll need to master if you want to work with the GA4 events data export in BigQuery</p> <p> Continue reading</p>"},{"location":"publications/medium/#google-pubsub-to-bigquery-the-simple-way","title":"Google Pub/Sub to BigQuery the simple way","text":"<p>A hands-on guide to implementing BigQuery Subscriptions in Pub/Sub for simple message and streaming ingestion</p> <p> Continue reading</p>"},{"location":"publications/medium/#getting-started-with-bigquery-sql-user-defined-functions-sql-udfs","title":"Getting Started with BigQuery SQL User Defined Functions (SQL UDFs)","text":"<p>A powerful and fundamental building block which enables custom extension of the core BigQuery platform functionality</p> <p> Continue reading</p>"},{"location":"publications/medium/#google-cloud-storage-gcs-to-bigquery-the-simple-way","title":"Google Cloud Storage (GCS) to BigQuery the simple way","text":"<p>Because simple is better than complex (but complex is better than complicated)</p> <p> Continue reading</p>"},{"location":"publications/medium/#how-to-build-a-unique-md5-row-hash-using-sql-in-bigquery-plus-a-few-related-things","title":"How to Build a Unique MD5 Row Hash Using SQL in BigQuery (Plus a Few Related Things)","text":"<p>Using native BigQuery functionality to generate a dynamic, unique row identifier in SQL</p> <p> Continue reading</p>"},{"location":"publications/medium/#plotting-bar-charts-in-bigquery-using-a-sql-user-defined-function-udf","title":"Plotting Bar Charts in BigQuery Using a SQL User Defined Function (UDF)","text":"<p>Minimise context switching and make your workflow faster</p> <p> Continue reading</p>"},{"location":"publications/medium/#sql-string-templating-in-bigquery-scripts-four-methods","title":"SQL String Templating in BigQuery Scripts: Four Methods","text":"<p>Powerful foundational techniques to help unlock the power of BigQuery scripting and automation</p> <p> Continue reading</p>"},{"location":"publications/medium/#getting-started-with-bigquery-scripting","title":"Getting Started with BigQuery Scripting","text":"<p>Demystifying this powerful but potentially difficult to grasp aspect of BigQuery functionality, one simple step at a time</p> <p> Continue reading</p>"},{"location":"publications/medium/#connecting-bigquery-to-colab-and-converting-query-results-to-python-dictionaries","title":"Connecting BigQuery to Colab and Converting Query Results to Python Dictionaries","text":"<p>A simple method for working with BigQuery results in Python (for pandaphobes)</p> <p> Continue reading</p>"},{"location":"reference/terminology/","title":"Terminology","text":"<p>The following definitions are used consistently across all functions and development activity.  These definitions may override some of the standard Google definitions which can be inconsistent across different system functions, views and user interfaces.</p>"},{"location":"reference/terminology/#resource-types","title":"Resource Types","text":"Resource Type  Description Docs  <code>TABLE</code> The collective terminology for a resource of type <code>BASE TABLE</code>, <code>PARTITIONED TABLE</code>, <code>SHARDED TABLE</code>, <code>EXTERNAL TABLE</code>, <code>SNAPSHOT</code> or <code>VIEW</code> Introduction to tables <code>BASE TABLE</code> A native BigQuery table, for which the data is physically stored within BigQuery Standard BigQuery tables <code>PARTITIONED TABLE</code> A native BigQuery table where the data is stored in physically separate partitions (typically using a <code>DATE</code> column), enabling efficient and performant query execution Partitioned tables <code>DATE-PARTITIONED TABLE (DPT)</code> A partitioned table which is partitioned by a specific date column. Partitioned tables <code>SHARDED TABLE</code> A set of tables with a common schema and prefix, but with distinct suffixes (e.g. <code>[prefix]_YYYYMMDD</code> for date-based sharding) Partitioning versus sharding <code>DATE-SHARDED TABLE (DST)</code> A sharded table which is sharded by date, with table names in the format <code>[prefix]_YYYYMMDD</code> Partitioning versus sharding <code>EXTERNAL TABLE</code> A BigQuery table where the data is stored externally, either within the Google ecosystem (Google Sheets, files on Google Cloud Storage) or externally (Amazon S3, Azure Blob Storage) External tables <code>SNAPSHOT</code> An efficient mechanism for recording point-in-time table contents Introduction to table snapshots <code>VIEW</code> An ephemeral table-like logical resource defined by a SQL query Views <code>ROUTINE</code> The collective terminology for a resource of type <code>FUNCTION</code>, <code>PROCEDURE</code>, <code>TABLE FUNCTION</code> or <code>REMOTE FUNCTION</code> Manage Routines <code>FUNCTION</code> User-defined code (SQL, native Javascript or packaged Javascript libraries) which wraps logic into a reusable and shareable function, taking zero or more type-specific arguments and returning a single value User-defined functions <code>PROCEDURE</code> A set of statements which takes zero or more type-specific arguments and enables complex logic and actions to be packaged into a single, reusable and shareable resource SQL stored procedures <code>TABLE FUNCTION (TF)</code> A parameterized <code>VIEW</code> which can support more complex, optimized query patterns Table functions <code>DATE-BOUNDED TABLE FUNCTION (DBTF)</code> A table function with precisely two <code>DATE</code> parameters as arguments: <code>start_date</code> and <code>end_date</code> Table functions <code>REMOTE FUNCTION</code> A Cloud Function written in one of a variety of languages which can be called like a BigQuery <code>FUNCTION</code>, enabling interaction with external APIs and libraries from BigQuery queries and workflows Work with remote functions <code>SCHEDULED QUERY</code> An arbitrary SQL statement which can be scheduled to run periodically Scheduling Queries"},{"location":"reference/terminology/#naming-conventions","title":"Naming Conventions","text":"Term  Data Type Description <code>project_id</code> <code>STRING</code> The globally unique identifier for each project <code>dataset_name</code> <code>STRING</code> The name for each dataset, unique in each project <code>dataset_id</code> <code>STRING</code> The globally unique identifier for each dataset, composed as <code>project_id.dataset_name</code> <code>resource_name</code> <code>STRING</code> The single name for each resource (<code>TABLE</code>, <code>VIEW</code>, <code>FUNCTION</code>, <code>TABLE FUNCTION</code> or <code>PROCEDURE</code>) <code>resource_id</code> <code>STRING</code> The globally unique identifier for an individual <code>TABLE</code>, <code>VIEW</code>, <code>FUNCTION</code>, <code>TABLE FUNCTION</code> or <code>PROCEDURE</code>, composed as <code>project_id.dataset_name.resource_name</code> <code>date_id</code> <code>STRING</code> A <code>STRING</code> representantion of a date in the format <code>YYYYMMDD</code> <code>shard_id</code> <code>STRING</code> A <code>STRING</code> representantion of a table shard date in the format <code>YYYYMMDD</code> <code>shard_date</code> <code>DATE</code> A <code>DATE</code> representantion of a table shard date <code>partition_id</code> <code>STRING</code> A <code>STRING</code> representantion of a table partition date in the format <code>YYYYMMDD</code> <code>partition_date</code> <code>DATE</code> A <code>DATE</code> representantion of a table partition date"},{"location":"reference/terminology/#language-types","title":"Language Types","text":"Language Type  Description Docs  GoogleSQL An ANSI compliant superset of Structured Query Language (SQL) SQL in BigQuery Procedural Language The core language which enables programmatic execution of arbitrary logic Procedural Language Data Definition Language Statements which enable creation and modification of BigQuery resources DDL Statements Data Manipulation Language Statements which enable insertion, deletion and modification of data DML Statements Data Control Language Statements which enable access control to BigQuery resources DCL Statements"},{"location":"reference/bqtools/","title":"Introduction","text":"<p>The BigQuery Tools (<code>bqtools</code>) library simplifies atomic data operations in BigQuery and enables functional programming and automation in the native BigQuery environment.</p>"},{"location":"reference/bqtools/#summary","title":"Summary","text":"Attribute Value Name BigQuery Tools Project ID <code>bqtools</code> Version <code>bqtools:v1.0.0</code> Access Private &amp; Client Description The low-level building blocks used to build, deploy and manage data automation solutions and products. It enables functional engineering within the native BigQuery environment."},{"location":"reference/bqtools/#deployment","title":"Deployment","text":"<p>Functions are currently deployed into the following BigQuery regions, but can be mirrored to additional regions as required:</p> Region Name Dataset ID EU <code>bqtools.eu</code> US <code>bqtools.us</code>"},{"location":"reference/bqtools/concepts/resources/","title":"Resources","text":"<p>Resources can be types of tables, views or routines, referenced by the <code>resource_id = project_id.dataset_name.resource_name</code>.</p>"},{"location":"reference/bqtools/concepts/resources/#date-bounded-table-function","title":"Date-Bounded Table Function","text":"<p>A table function is identical to a view, except it can accept arguments.  This is especially useful when working with date-partitioned or date-sharded source data, as by using <code>start_date</code> and <code>end_date</code> as table function <code>DATE</code> arguments, only the specific date range requested is queried or billed for. A Date-Bounded Table Function (DBTF) has precisely two <code>DATE</code> parameters as arguments: <code>start_date</code> and <code>end_date</code>.</p> <p>The syntax for creating a Date-Bounded Table Function is:</p> <pre><code>CREATE OR REPLACE TABLE FUNCTION `project_id.dataset_id.transform_function_name` (start_date DATE, end_date DATE)\nAS\nWITH get_source_data AS (\n    SELECT * \n    FROM `project_id.dataset_id.table_name`\n    WHERE date_column BETWEEN start_date AND end_date)...\n\n    [...]\n\nSELECT *\nFROM ...\n</code></pre> <p>Note that using the <code>start_date</code> and <code>end_date</code> <code>DATE</code> arguments in the query is optional, but they must be defined as table function arguments.</p>"},{"location":"reference/bqtools/functions/automation/","title":"Automation","text":"<p>These functions are used to efficiently automate data flowing through BigQuery.</p>"},{"location":"reference/bqtools/functions/automation/#run-flow","title":"RUN flow","text":"Attribute Value Function Name <code>run_flow</code> ID <code>bqtools.[region].run_flow</code> Version <code>bqtools:v1.0.0</code> Description Runs a single, idempotent execution of a logical flow, defined by a date-partitioned or date-sharded data source, a transformation/augmentation date-bounded table function, a destination table and a set of execution and deployment options. Type <code>PROCEDURE</code> Arguments <code>source_table_id STRING, transform_resource_id STRING, destination_table_id STRING, execution_options JSON, destination_table_options JSON</code> Returns <code>None</code> Dependencies <code>bqtools.[region].parse_resource_id</code>, <code>bqtools.[region].get_first_date_shard</code>, <code>bqtools.[region].get_last_date_shard</code>, <code>bqtools.[region].get_first_date_partition</code>, <code>bqtools.[region].get_last_date_partition</code>, <code>bqtools.[region].create_table_from_date_bounded_table_function</code>, <code>bqtools.[region].replace_date_partitions_from_date_bounded_table_function</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE source_table_id, transform_resource_id, destination_table_id STRING;\nDECLARE execution_options,  destination_table_options JSON;\n\nSET source_table_id = 'project_id.analytics_1234.events_';\nSET transform_resource_id = 'project_id.analytics_1234.GA4_EVENTS';\nSET destination_table_id = 'project_id.analytics_1234.events';\n\nCALL bqtools.eu.run_flow(\n    source_table_id, \n    transform_resource_id, \n    destination_table_id, \n    execution_options, \n    destination_table_options);\n</code></pre> <pre><code>DECLARE source_table_id, transform_resource_id, destination_table_id STRING;\nDECLARE execution_options,  destination_table_options JSON;\n\nSET source_table_id = 'project_id.analytics_1234.events_';\nSET transform_resource_id = 'project_id.analytics_1234.GA4_EVENTS';\nSET destination_table_id = 'project_id.analytics_1234.events';\n\nCALL bqtools.us.run_flow(\n    source_table_id, \n    transform_resource_id, \n    destination_table_id, \n    execution_options, \n    destination_table_options);\n</code></pre> <p>ARGUMENTS</p> ARGUMENT DATA TYPE DESCRIPTION source_table_id STRING The source date-partitioned or date-sharded data table. transform_resource_id STRING The source date-bounded table function defining the transformation. destination_table_id STRING The destination date-partitioned table. execution_options JSON Options to configure specific executions. destination_table_options JSON Deployment options for the destination table. <p>For sharded table types, include the trailing underscore in the source_table_id (e.g. <code>project_id.analytics1234.events_</code>).</p> EXECUTION OPTIONS execution_optionsExamples Option Data Type Values JSON Path Default Description EXECUTION MODE STRING <code>full</code>, <code>incremental</code>, <code>date_range</code> <code>execution_mode</code> <code>incremental</code> Flow execution mode. DATES TO REPLACE INT64 Integer value <code>replace_additional_date_partitions</code> <code>0</code> Additional historic date partitions to replace in <code>incremental</code> mode. START DATE DATE Date value <code>start_date</code> Start date in <code>date_range</code> mode. END DATE DATE Date value <code>end_date</code> End date in <code>date_range</code> mode. <p>Note that a <code>NULL</code> value for the <code>execution</code> mode will execute an <code>incremental</code> flow on only the latest arriving date partitions. </p> Full <pre><code>SET execution_options = JSON '{\"execution_mode\": \"full\"}';\n</code></pre> Incremental <pre><code>SET execution_options = JSON '{\"execution_mode\": \"incremental\", \"replace_additional_date_partitions\": 4}';\n</code></pre> Full Date Range <pre><code>SET execution_options = JSON '{\"execution_mode\": \"date_range\", \"start_date\": \"2024-01-01\", \"end_date\": \"2024-01-31\"}';\n</code></pre> Start Date Range <pre><code>SET execution_options = JSON '{\"execution_mode\": \"date_range\", \"end_date\": \"2024-01-31\"}';\n</code></pre> End Date Range <pre><code>SET execution_options = JSON '{\"execution_mode\": \"date_range\", \"start_date\": \"2024-01-01\"}';\n</code></pre> DESTINATION TABLE OPTIONS destination_table_optionsExample Option Data Type Values JSON Path Default Description PARTITION EXPRESSION STRING Partition expression or column partition_expression <code>None</code> Destination table partitioning specification. CLUSTERING COLUMN LIST ARRAY Clustering columns clustering_column_list <code>None</code> Destination table clustering specification. DESCRIPTION STRING Description description <code>None</code> Destination table description. <p>The following <code>destination_table_options</code> configuration in <code>full</code> execution mode will build the destination table as a date partitioned table, partitioned on the <code>event_date</code> column, clustered on the <code>session_id</code>column and with \"Event-level aggregation\" as the table description.  </p> <pre><code>SET destination_table_options = JSON'{\"description\": \"Event-level aggregation\", \"clustering_column_list\": [\"session_id\"], \"partition_expression\": \"event_date\"}';\n</code></pre> <p>Note that in <code>incremental</code> and <code>date_range</code> execution modes, the destination table is not rebuilt, so the <code>destination_table_options</code> is ignored and a <code>NULL</code> value can be passed without impact to execution behaviour.</p>"},{"location":"reference/bqtools/functions/export/","title":"Export","text":"<p>These functions are used to automate data export from BigQuery.</p>"},{"location":"reference/bqtools/functions/export/#export-data","title":"EXPORT data","text":"Attribute Value Function Name <code>export_data</code> ID <code>bqtools.[region].export_data</code> Version <code>bqtools:v1.0.0</code> Description Exports data to Google Cloud Storage or Amazon S3 bucket, with export options aligned to the EXPORT DATA statement. Type <code>PROCEDURE</code> Arguments <code>export_options JSON</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].export_data</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE export_options JSON;\n\nSET export_options = JSON '{...}';\n\nCALL bqtools.eu.export_data(export_options);\n</code></pre> <pre><code>DECLARE export_options JSON;\n\nSET export_options = JSON '{...}';\n\nCALL bqtools.us.export_data(export_options)\n</code></pre> <p>ARGUMENTS</p> ARGUMENT DATA TYPE DESCRIPTION export_options JSON Options to configure specific exports, aligned with to the EXPORT DATA statement. EXPORT OPTIONS export_optionsExamples Option Data Type Values JSON Path Default Description query_statement STRING SQL Query <code>query_statement</code> <code>REQUIRED</code> An SQL query. The query result is exported to the external destination. format STRING AVRO, CSV, JSON, PARQUET <code>format</code> <code>REQUIRED</code> The format of the exported data. uri STRING Single-wildcard GCS URI <code>uri</code> <code>REQUIRED</code> The destination URI for the export. connection_name STRING <code>PROJECT_ID.LOCATION.CONNECTION_ID</code> <code>connection_name</code> <code>None</code> Specifies a connection that has credentials for accessing the external data. compression STRING GZIP, DEFLATE, SNAPPY <code>compression</code> <code>None</code> Specifies a compression format. If not specified, the exported files are uncompressed. overwrite BOOL <code>true</code>/<code>false</code> <code>overwrite</code> <code>false</code> If true, overwrites any existing files with the same URI. Otherwise, if the destination storage bucket is not empty, the statement returns an error. header BOOL <code>true</code>/<code>false</code> <code>header</code> <code>false</code> If true, generates column headers for the first row of each data file. Applies to: CSV. field_delimiter STRING Delimiter string <code>field_delimiter</code> <code>,</code> (comma) The delimiter used to separate fields. use_avro_logical_types BOOL <code>true</code>/<code>false</code> <code>use_avro_logical_types</code> <code>false</code> Whether to use appropriate AVRO logical types when exporting TIMESTAMP, DATETIME, TIME and DATE types. Applies to: AVRO <p>Examples are aligned to the BigQuery EXPORT DATA statement examples.</p> Export data to Cloud Storage in CSV format OriginalFunctional <pre><code>EXPORT DATA \nOPTIONS (\n    uri='gs://bucket/folder/*.csv',\n    format='CSV',\n    overwrite=true,\n    header=true,\n    field_delimiter=';') \nAS\nSELECT field1, field2 \nFROM mydataset.table1 \nORDER BY field1 LIMIT 10\n</code></pre> <pre><code>DECLARE export_options JSON;\nSET export_options = JSON \"\"\"{\n    \"uri\": \"gs://bucket/folder/*.csv\",\n    \"format\": \"CSV\",\n    \"overwrite\": true,\n    \"header\": true,\n    \"field_delimiter\": \";\",\n    \"query_statement\": \"SELECT field1, field2 FROM mydataset.table1 ORDER BY field1 LIMIT 10\"\n    }\"\"\";\n\nCALL bqtools.us.export_data(export_options)\n</code></pre>"},{"location":"reference/bqtools/functions/metadata/","title":"Metadata","text":"<p>These functions are used to query resource metadata to support efficient, automated data workflows.</p>"},{"location":"reference/bqtools/functions/metadata/#get-date-partitions","title":"GET Date Partitions","text":"Attribute Value Function Name <code>get_date_partitions</code> ID <code>bqtools.[region].get_date_partitions</code> Version <code>bqtools:v1.0.0</code> Description Returns an array of dates corresponding to all existing partitions in a single partitioned table, sorted by descending date. Type <code>PROCEDURE</code> Arguments <code>partitioned_table_id STRING, OUT partitions ARRAY&lt;DATE&gt;</code> Returns <code>OUT partitions ARRAY&lt;DATE&gt;</code> Dependencies <code>bqtools-qb.[region].get_date_partitions</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE partitioned_table_id STRING;\nDECLARE partitions ARRAY&lt;DATE&gt;;\n\nSET partitioned_table_id = 'project_id.dataset_name.partitioned_table_name';\n\nCALL bqtools.eu.get_date_partitions(partitioned_table_id, partitions);\n</code></pre> <pre><code>DECLARE partitioned_table_id STRING;\nDECLARE partitions ARRAY&lt;DATE&gt;;\n\nSET partitioned_table_id = 'project_id.dataset_name.partitioned_table_name';\n\nCALL bqtools.us.get_date_partitions(partitioned_table_id, partitions);\n</code></pre>"},{"location":"reference/bqtools/functions/metadata/#get-first-date-partition","title":"GET First Date Partition","text":"Attribute Value Function Name <code>get_first_date_partition</code> ID <code>bqtools.[region].get_first_date_partition</code> Version <code>bqtools:v1.0.0</code> Description Returns the first partition date from a single date-partitioned table. Type <code>PROCEDURE</code> Arguments <code>partitioned_table_id STRING, OUT first_partition DATE</code> Returns <code>OUT first_partition DATE</code> Dependencies <code>bqtools.[region].get_date_partitions</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE partitioned_table_id STRING;\nDECLARE first_partition DATE;\n\nSET partitioned_table_id = 'project_id.dataset_name.partitioned_table_name';\n\nCALL bqtools.eu.get_first_date_partition(partitioned_table_id, first_partition);\n</code></pre> <pre><code>DECLARE partitioned_table_id STRING;\nDECLARE first_partition DATE;\n\nSET partitioned_table_id = 'project_id.dataset_name.partitioned_table_name';\n\nCALL bqtools.us.get_first_date_partition(partitioned_table_id, first_partition);\n</code></pre>"},{"location":"reference/bqtools/functions/metadata/#get-last-date-partition","title":"GET Last Date Partition","text":"Attribute Value Function Name <code>get_last_date_partition</code> ID <code>bqtools.[region].get_last_date_partition</code> Version <code>bqtools:v1.0.0</code> Description Returns the last partition date from a single date-partitioned table. Type <code>PROCEDURE</code> Arguments <code>partitioned_table_id STRING, OUT last_partition DATE</code> Returns <code>OUT last_partition DATE</code> Dependencies <code>bqtools.[region].get_date_partitions</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE partitioned_table_id STRING;\nDECLARE last_partition DATE;\n\nSET partitioned_table_id = 'project_id.dataset_name.partitioned_table_name';\n\nCALL bqtools.eu.get_last_date_partition(partitioned_table_id, last_partition);\n</code></pre> <pre><code>DECLARE partitioned_table_id STRING;\nDECLARE last_partition DATE;\n\nSET partitioned_table_id = 'project_id.dataset_name.partitioned_table_name';\n\nCALL bqtools.us.get_last_date_partition(partitioned_table_id, last_partition);\n</code></pre>"},{"location":"reference/bqtools/functions/metadata/#get-date-shards","title":"GET Date Shards","text":"Attribute Value Function Name <code>get_date_shards</code> ID <code>bqtools.[region].get_date_shards</code> Version <code>bqtools:v1.0.0</code> Description Returns an array of <code>shard_dates</code> corresponding to all existing date shards in a single date-sharded table, sorted by descending date. Type <code>PROCEDURE</code> Arguments <code>sharded_table_dataset_id STRING, sharded_table_prefix STRING, OUT shard_dates ARRAY&lt;DATE&gt;</code> Returns <code>OUT shard_dates ARRAY&lt;DATE&gt;</code> Dependencies <code>bqtools-qb.[region].get_date_shards</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE sharded_table_dataset_id, sharded_table_prefix STRING;\nDECLARE shard_dates ARRAY&lt;DATE&gt;;\n\nSET sharded_table_dataset_id = 'project_id.dataset_name';\nSET sharded_table_prefix = 'my_table_prefix_';\n\nCALL bqtools.eu.get_date_shards(sharded_table_dataset_id, sharded_table_prefix, shard_dates);\n</code></pre> <pre><code>DECLARE sharded_table_dataset_id, sharded_table_prefix STRING;\nDECLARE shard_dates ARRAY&lt;DATE&gt;;\n\nSET sharded_table_dataset_id = 'project_id.dataset_name';\nSET sharded_table_prefix = 'my_table_prefix_';\n\nCALL bqtools.us.get_date_shards(sharded_table_dataset_id, sharded_table_prefix, shard_dates);\n</code></pre>"},{"location":"reference/bqtools/functions/metadata/#get-first-date-shard","title":"GET First Date Shard","text":"Attribute Value Function Name <code>get_first_date_shard</code> ID <code>bqtools.[region].get_first_date_shard</code> Version <code>bqtools:v1.0.0</code> Description Returns the first <code>shard_date</code> from a single sharded table. Type <code>PROCEDURE</code> Arguments <code>sharded_table_dataset_id STRING, sharded_table_prefix STRING, OUT first_shard DATE</code> Returns <code>OUT first_shard DATE</code> Dependencies <code>bqtools.[region].get_date_shards</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE sharded_table_dataset_id, sharded_table_prefix STRING;\nDECLARE first_shard DATE;\n\nSET sharded_table_dataset_id = 'project_id.dataset_name';\nSET sharded_table_prefix = 'my_table_prefix_';\n\nCALL bqtools.eu.get_first_date_shard(sharded_table_dataset_id, sharded_table_prefix, first_shard);\n</code></pre> <pre><code>DECLARE sharded_table_dataset_id, sharded_table_prefix STRING;\nDECLARE first_shard DATE;\n\nSET sharded_table_dataset_id = 'project_id.dataset_name';\nSET sharded_table_prefix = 'my_table_prefix_';\n\nCALL bqtools.us.get_first_date_shard(sharded_table_dataset_id, sharded_table_prefix, first_shard);\n</code></pre>"},{"location":"reference/bqtools/functions/metadata/#get-last-date-shard","title":"GET Last Date Shard","text":"Attribute Value Function Name <code>get_last_date_shard</code> ID <code>bqtools.[region].get_last_date_shard</code> Version <code>bqtools:v1.0.0</code> Description Returns the last <code>shard_date</code> from a single date-sharded table. Type <code>PROCEDURE</code> Arguments <code>sharded_table_dataset_id STRING, sharded_table_prefix STRING, OUT last_shard DATE</code> Returns <code>OUT last_shard DATE</code> Dependencies <code>bqtools.[region].get_date_shards</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE sharded_table_dataset_id, sharded_table_prefix STRING;\nDECLARE last_shard DATE;\n\nSET sharded_table_dataset_id = 'project_id.dataset_name';\nSET sharded_table_prefix = 'my_table_prefix_';\n\nCALL bqtools.eu.get_last_date_shard(sharded_table_dataset_id, sharded_table_prefix, last_shard);\n</code></pre> <pre><code>DECLARE sharded_table_dataset_id, sharded_table_prefix STRING;\nDECLARE last_shard DATE;\n\nSET sharded_table_dataset_id = 'project_id.dataset_name';\nSET sharded_table_prefix = 'my_table_prefix_';\n\nCALL bqtools.us.get_last_date_shard(sharded_table_dataset_id, sharded_table_prefix, last_shard);\n</code></pre>"},{"location":"reference/bqtools/functions/partitions/","title":"Partitions","text":"<p>These functions support creation, insertion and deletion of data partitions to support composition of idempotent data operations.</p>"},{"location":"reference/bqtools/functions/partitions/#delete-date-partitions","title":"DELETE Date Partitions","text":"Attribute Value Function Name <code>delete_date_partitions</code> ID <code>bqtools.[region].delete_date_partitions</code> Version <code>bqtools:v1.0.0</code> Description Deletes a range of date-partitions from a date-partitioned destination table. Type <code>PROCEDURE</code> Arguments <code>table_id STRING, date_column_name STRING, start_date DATE, end_date DATE</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].delete_date_partitions</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE destination_table_id, date_column_name STRING;\nDECLARE start_date, end_date DATE;\n\nSET destination_table_id = 'project_id.dataset_name.partitioned_table_name';\nSET date_column_name = 'event_date';\nSET start_date = CURRENT_DATE - 7;\nSET end_date = CURRENT_DATE;\n\nCALL bqtools.eu.delete_date_partitions(destination_table_id, event_date, date_column_name, start_date, end_date);\n</code></pre> <pre><code>DECLARE destination_table_id, date_column_name STRING;\nDECLARE start_date, end_date DATE;\n\nSET destination_table_id = 'project_id.dataset_name.partitioned_table_name';\nSET date_column_name = 'event_date';\nSET start_date = CURRENT_DATE - 7;\nSET end_date = CURRENT_DATE;\n\nCALL bqtools.us.delete_date_partitions(destination_table_id, event_date, date_column_name, start_date, end_date);\n</code></pre>"},{"location":"reference/bqtools/functions/partitions/#insert-date-partitions","title":"INSERT Date Partitions","text":"Attribute Value Function Name <code>insert_date_partitions_from_date_bounded_table_function</code> ID <code>bqtools.[region].insert_date_partitions_from_date_bounded_table_function</code> Version <code>bqtools:v1.0.0</code> Description Inserts a range of date partitions from a date-bounded table function into a date-partitioned destination table. Type <code>PROCEDURE</code> Arguments <code>destination_table_id STRING, source_table_function_id STRING, start_date DATE, end_date DATE</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].insert_date_partitions_from_date_bounded_table_function</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE destination_table_id, source_table_function_id STRING;\nDECLARE start_date, end_date DATE;\n\nSET destination_table_id = 'project_id.dataset_name.partitioned_table_name';\nSET source_table_function_id = 'project_id.dataset_name.table_function_name';\n\nSET start_date = CURRENT_DATE - 7;\nSET end_date = CURRENT_DATE;\n\nCALL bqtools.eu.insert_date_partitions_from_date_bounded_table_function(destination_table_id, source_table_function_id, start_date, end_date);\n</code></pre> <pre><code>DECLARE destination_table_id, source_table_function_id STRING;\nDECLARE start_date, end_date DATE;\n\nSET destination_table_id = 'project_id.dataset_name.partitioned_table_name';\nSET source_table_function_id = 'project_id.dataset_name.table_function_name';\n\nSET start_date = CURRENT_DATE - 7;\nSET end_date = CURRENT_DATE;\n\nCALL bqtools.us.insert_date_partitions_from_date_bounded_table_function(destination_table_id, source_table_function_id, start_date, end_date);\n</code></pre>"},{"location":"reference/bqtools/functions/partitions/#replace-date-partitions","title":"REPLACE Date Partitions","text":"Attribute Value Function Name <code>replace_date_partitions_from_date_bounded_table_function</code> ID <code>bqtools.[region].replace_date_partitions_from_date_bounded_table_function</code> Version <code>bqtools:v1.0.0</code> Description Deletes a range of date partitions from a date-partitioned destination table and inserts the same range of date partitions from a date-bounded table function. Type <code>PROCEDURE</code> Arguments <code>destination_table_id STRING, date_column_name STRING, source_table_function_id STRING, start_date DATE, end_date DATE</code> Returns <code>None</code> Dependencies <code>bqtools.[region].delete_date_partitions</code>, <code>bqtools.[region].insert_date_partitions_from_date_bounded_table_function</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE destination_table_id, date_column_name, source_table_function_id STRING;\nDECLARE start_date, end_date DATE;\n\nSET destination_table_id = 'project_id.dataset_name.partitioned_table_name';\nSET date_column_name = 'event_date';\nSET source_table_function_id = 'project_id.dataset_name.table_function_name';\n\nSET start_date = CURRENT_DATE - 7;\nSET end_date = CURRENT_DATE;\n\nCALL bqtools.eu.replace_date_partitions_from_date_bounded_table_function(destination_table_id, date_column_name, source_table_function_id, start_date, end_date);\n</code></pre> <pre><code>DECLARE destination_table_id, date_column_name, source_table_function_id STRING;\nDECLARE start_date, end_date DATE;\n\nSET destination_table_id = 'project_id.dataset_name.partitioned_table_name';\nSET date_column_name = 'event_date';\nSET source_table_function_id = 'project_id.dataset_name.table_function_name';\n\nSET start_date = CURRENT_DATE - 7;\nSET end_date = CURRENT_DATE;\n\nCALL bqtools.us.replace_date_partitions_from_date_bounded_table_function(destination_table_id, date_column_name, source_table_function_id, start_date, end_date);\n</code></pre>"},{"location":"reference/bqtools/functions/resources/","title":"Resources","text":"<p>These functions are used to create resources from SQL definitions and deployment-specific options.</p>"},{"location":"reference/bqtools/functions/resources/#create-function","title":"CREATE Function","text":"Attribute Value Name <code>create_function</code> ID <code>bqtools.[region].create_function</code> Version <code>bqtools:v1.0.0</code> Description Creates or replaces a sql user-defined function defined by an arbitrary query statement and a set of deployment options. Type <code>PROCEDURE</code> Arguments <code>function_id STRING, query_statement STRING, function_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;, function_options JSON</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].create_function</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE function_id, query_statement STRING;\nDECLARE function_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;;\nDECLARE function_options JSON;\n\nSET function_id = 'project_id.dataset_name.function_name';\nSET function_arguments = [(\"string_argument\", \"STRING\")];\nSET query_statement = 'SELECT 1 AS example';\n\nSELECT bqtools.eu.create_function(function_id, query_statement, function_arguments, function_options);\n</code></pre> <pre><code>DECLARE function_id, query_statement STRING;\nDECLARE function_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;;\nDECLARE function_options JSON DEFAULT JSON '{}';\n\nSET function_id = 'project_id.dataset_name.function_name';\nSET function_arguments = [(\"string_argument\", \"STRING\")];\nSET query_statement = 'SELECT 1 AS example';\n\nSELECT bqtools.us.create_function(function_id, query_statement, function_arguments, function_options);\n</code></pre> OPTIONS OptionsDefault Options <p>The following deployment options can be set using the <code>function_options</code> <code>JSON</code> argument, which is a subset of the CREATE FUNCTION DDL options.</p> Option Option Data Type Values JSON Path Default REPLACE <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>replace_function</code> <code>true</code> TEMPORARY <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>temporary_function</code> <code>false</code> IF NOT EXISTS <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>if_not_exists</code> <code>false</code> DESCRIPTION <code>STRING</code> <code>Function description</code> <code>description</code> <code>None</code> <p>If the <code>function_options</code> <code>JSON</code> argument is <code>NULL</code>, the default options will correspond to the following DDL statement:</p> <pre><code>CREATE OR REPLACE FUNCTION `[function_id]`([function_arguments])\nAS\n[query_statement]\n</code></pre>"},{"location":"reference/bqtools/functions/resources/#create-procedure","title":"CREATE Procedure","text":"Attribute Value Name <code>create_procedure</code> ID <code>bqtools.[region].create_procedure</code> Version <code>bqtools:v1.0.0</code> Description Creates or replaces a sql user-defined function defined by an arbitrary query statement and a set of deployment options. Type <code>PROCEDURE</code> Arguments <code>procedure_id STRING, query_statement STRING, procedure_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;, procedure_options JSON</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].create_procedure</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE procedure_id, query_statement STRING;\nDECLARE procedure_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;;\nDECLARE procedure_options JSON DEFAULT JSON '{}';\n\nSET procedure_id = 'project_id.dataset_name.procedure_name';\nSET procedure_arguments = [(\"string_argument\", \"STRING\")];\n\nSELECT bqtools.eu.create_procedure(procedure_id, query_statement, procedure_arguments, procedure_options);\n</code></pre> <pre><code>DECLARE procedure_id, query_statement STRING;\nDECLARE procedure_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;;\nDECLARE procedure_options JSON;\n\nSET procedure_id = 'project_id.dataset_name.procedure_name';\nSET procedure_arguments = [(\"string_argument\", \"STRING\")];\n\nSELECT bqtools.us.create_procedure(procedure_id, query_statement, procedure_arguments, procedure_options);\n</code></pre> OPTIONS OptionsDefault Options <p>The following deployment options can be set using the <code>procedure_options</code> <code>JSON</code> argument, which is a subset of the CREATE PROCEDURE DDL options.</p> Option Option Data Type Values JSON Path Default REPLACE <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>replace_procedure</code> <code>true</code> TEMPORARY <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>temporary_procedure</code> <code>false</code> IF NOT EXISTS <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>if_not_exists</code> <code>false</code> DESCRIPTION <code>STRING</code> <code>Function description</code> <code>description</code> <code>None</code> <p>If the <code>procedure_options</code> <code>JSON</code> argument is <code>NULL</code>, the default options will correspond to the following DDL statement:</p> <pre><code>CREATE OR REPLACE PROCEDURE `[procedure_id]`([procedure_arguments])\nAS\n[query_statement]\n</code></pre>"},{"location":"reference/bqtools/functions/resources/#create-table","title":"CREATE Table","text":"Attribute Value Name <code>create_table</code> ID <code>bqtools.[region].create_table</code> Version <code>bqtools:v1.0.0</code> Description Creates or replaces a single base table as the results of an arbitrary sql statement and a set of deployment options. Type <code>PROCEDURE</code> Arguments <code>table_id STRING, query_statement STRING, table_options JSON</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].create_table</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE table_id, query_statement STRING;\nDECLARE table_options JSON;\n\nSET table_id = 'project_id.dataset_name.table_name';\n\nSELECT bqtools.eu.create_table(table_id, query_statement, table_options);\n</code></pre> <pre><code>DECLARE table_id, query_statement STRING;\nDECLARE table_options JSON DEFAULT JSON '{}';\n\nSET table_id = 'project_id.dataset_name.table_name';\n\nSELECT bqtools.us.create_table(table_id, query_statement, table_options);\n</code></pre> OPTIONS OptionsDefault Options <p>The following deployment options can be set using the <code>table_options</code> <code>JSON</code> argument, which is a subset of the CREATE TABLE DDL options.</p> Option Option Data Type Values JSON Path Default REPLACE <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>replace_procedure</code> <code>true</code> TEMPORARY <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>temporary_procedure</code> <code>false</code> IF NOT EXISTS <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>if_not_exists</code> <code>false</code> DESCRIPTION <code>STRING</code> <code>Function description</code> <code>description</code> <code>None</code> PARTITION EXPRESSION <code>STRING</code> <code>Partition expression</code> <code>partition_expression</code> <code>None</code> CLUSTERING COLUMN LIST <code>ARRAY&lt;STRING&gt;</code> <code>Clustering columns</code> <code>clustering_column_list</code> <code>None</code> EXPIRATION TIMESTAMP <code>STRING</code> <code>Timestamp</code> <code>expiration_timestamp</code> <code>None</code> PARTITION EXPIRATION DAYS <code>INTEGER</code> <code>Integer</code> <code>partition_expiration_days</code> <code>None</code> REQUIRE PARTITION FILTER <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>require_partition_filter</code> <code>false</code> KMS KEY NAME <code>STRING</code> <code>KMS key name</code> <code>kms_key_name</code> <code>None</code> FRIENDLY NAME <code>STRING</code> <code>Friendly name</code> <code>friendly_name</code> <code>None</code> DEFAULT ROUNDING MODE <code>STRING</code> <code>Default rounding mode</code> <code>default_rounding_mode</code> <code>None</code> <p>If the <code>table_options</code> <code>JSON</code> argument is <code>NULL</code>, the default options will correspond to the following DDL statement:</p> <pre><code>CREATE OR REPLACE TABLE `[procedure_id]`\nAS\n[query_statement]\n</code></pre>"},{"location":"reference/bqtools/functions/resources/#create-table-function","title":"CREATE Table Function","text":"Attribute Value Name <code>create_table_function</code> ID <code>bqtools.[region].create_table_function</code> Version <code>bqtools:v1.0.0</code> Description Creates or replaces a table function defined by an arbitrary sql statement and a set of deployment options. Type <code>PROCEDURE</code> Arguments <code>table_function_id STRING, query_statement STRING, table_function_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;, table_function_options JSON</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].create_table_function</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE table_function_id, query_statement STRING;\nDECLARE table_function_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;;\nDECLARE table_function_options JSON;\n\nSET table_function_id = 'project_id.dataset_name.table_function_name';\nSET table_function_arguments = [(\"string_argument\", \"STRING\")];\nSET query_statement = 'SELECT 1 AS example';\n\nSELECT bqtools.eu.create_table_function(table_function_id, query_statement, table_function_arguments, table_function_options);\n</code></pre> <pre><code>DECLARE table_function_id, query_statement STRING;\nDECLARE table_function_arguments ARRAY&lt;STRUCT&lt;name STRING, data_type STRING&gt;&gt;;\nDECLARE table_function_options JSON;\n\nSET table_function_id = 'project_id.dataset_name.table_function_name';\nSET table_function_arguments = [(\"string_argument\", \"STRING\")];\nSET query_statement = 'SELECT 1 AS example';\n\nSELECT bqtools.us.create_table_function(table_function_id, query_statement, table_function_arguments, table_function_options);\n</code></pre> OPTIONS OptionsDefault Options <p>The following deployment options can be set using the <code>table_function_options</code> <code>JSON</code> argument, which is a subset of the CREATE TABLE FUNCTION DDL options.</p> Option Option Data Type Values JSON Path Default REPLACE <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>replace_procedure</code> <code>true</code> IF NOT EXISTS <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>if_not_exists</code> <code>false</code> DESCRIPTION <code>STRING</code> <code>Function description</code> <code>description</code> <code>None</code> <p>If the <code>function_options</code> <code>JSON</code> argument is <code>NULL</code>, the default options will correspond to the following DDL statement:</p> <pre><code>CREATE OR REPLACE TABLE FUNCTION `[procedure_id]`([procedure_arguments])\nAS\n[query_statement]\n</code></pre>"},{"location":"reference/bqtools/functions/resources/#create-table-from-dbtf","title":"CREATE Table from DBTF","text":"Attribute Value Name <code>create_table_from_date_bounded_table_function</code> ID <code>bqtools.[region].create_table_from_date_bounded_table_function</code> Version <code>bqtools:v1.0.0</code> Description Creates or replaces a single base table as a date partition range from a date-bounded table function, with a set of deployment options. Type <code>PROCEDURE</code> Arguments <code>destination_table_id STRING, source_table_function_id STRING, start_date DATE, end_date DATE, table_options JSON</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].create_table</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE destination_table_id, source_table_function_id STRING;\nDECLARE start_date, end_date DATE;\nDECLARE table_options JSON;\n\nSET destination_table_id = 'project_id.dataset_name.destination_table_name';\nSET source_table_function_id = 'project_id.dataset_name.source_table_function_name';\n\nSELECT bqtools.eu.create_table_function(table_function_id, query_statement, table_function_arguments, table_function_options);\n</code></pre> <pre><code>DECLARE destination_table_id, source_table_function_id STRING;\nDECLARE start_date, end_date DATE;\nDECLARE table_options JSON;\n\nSET destination_table_id = 'project_id.dataset_name.destination_table_name';\nSET source_table_function_id = 'project_id.dataset_name.source_table_function_name';\n\nSELECT bqtools.us.create_table_function(table_function_id, query_statement, table_function_arguments, table_function_options);\n</code></pre> OPTIONS OptionsDefault Options <p>The following deployment options can be set using the <code>table_options</code> <code>JSON</code> argument, which is a subset of the CREATE TABLE DDL options.</p> Option Option Data Type Values JSON Path Default REPLACE <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>replace_procedure</code> <code>true</code> TEMPORARY <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>temporary_procedure</code> <code>false</code> IF NOT EXISTS <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>if_not_exists</code> <code>false</code> DESCRIPTION <code>STRING</code> <code>Function description</code> <code>description</code> <code>None</code> PARTITION EXPRESSION <code>STRING</code> <code>Partition expression</code> <code>partition_expression</code> <code>None</code> CLUSTERING COLUMN LIST <code>ARRAY&lt;STRING&gt;</code> <code>Clustering columns</code> <code>clustering_column_list</code> <code>None</code> EXPIRATION TIMESTAMP <code>STRING</code> <code>Timestamp</code> <code>expiration_timestamp</code> <code>None</code> PARTITION EXPIRATION DAYS <code>INTEGER</code> <code>Integer</code> <code>partition_expiration_days</code> <code>None</code> REQUIRE PARTITION FILTER <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>require_partition_filter</code> <code>false</code> KMS KEY NAME <code>STRING</code> <code>KMS key name</code> <code>kms_key_name</code> <code>None</code> FRIENDLY NAME <code>STRING</code> <code>Friendly name</code> <code>friendly_name</code> <code>None</code> DEFAULT ROUNDING MODE <code>STRING</code> <code>Default rounding mode</code> <code>default_rounding_mode</code> <code>None</code> <p>If the <code>table_options</code> <code>JSON</code> argument is <code>NULL</code>, the default options will correspond to the following DDL statement:</p> <pre><code>CREATE OR REPLACE TABLE `[destination_table_id]`\nAS\nSELECT * FROM `[source_table_function_id]`([start_date], [end_date])\n</code></pre>"},{"location":"reference/bqtools/functions/resources/#create-view","title":"CREATE View","text":"Attribute Value Name <code>create_view</code> ID <code>bqtools.[region].create_view</code> Version <code>bqtools:v1.0.0</code> Description Creates or replaces a single view defined by an arbitrary sql statement and a set of deployment options. Type <code>PROCEDURE</code> Arguments <code>view_id STRING, query_statement STRING, view_options JSON</code> Returns <code>None</code> Dependencies <code>bqtools-qb.[region].create_view</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE view_id, query_statement STRING;\nDECLARE view_options JSON;\n\nSET view_id = 'project_id.dataset_name.view_name';\nSET query_statement = 'SELECT 1 AS example';\n\nSELECT bqtools.eu.create_view(view_id, query_statement, view_options);\n</code></pre> <pre><code>DECLARE view_id, query_statement STRING;\nDECLARE view_options JSON;\n\nSET view_id = 'project_id.dataset_name.view_name';\nSET query_statement = 'SELECT 1 AS example';\n\nSELECT bqtools.us.create_view(view_id, query_statement, view_options);\n</code></pre> OPTIONS OptionsDefault Options <p>The following deployment options can be set using the <code>view_options</code> <code>JSON</code> argument, which is a subset of the CREATE VIEW DDL options.</p> Option Option Data Type Values JSON Path Default REPLACE <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>replace_view</code> <code>true</code> IF NOT EXISTS <code>BOOLEAN</code> <code>true</code>/<code>false</code> <code>if_not_exists</code> <code>false</code> DESCRIPTION <code>STRING</code> <code>View description</code> <code>description</code> <code>None</code> EXPIRATION TIMESTAMP <code>STRING</code> <code>Timestamp</code> <code>expiration_timestamp</code> <code>None</code> FRIENDLY NAME <code>STRING</code> <code>Friendly name</code> <code>friendly_name</code> <code>None</code> <p>If the <code>view_options</code> <code>JSON</code> argument is <code>NULL</code>, the default options will correspond to the following DDL statement:</p> <pre><code>CREATE OR REPLACE VIEW `[view_id]`\nAS\n[query_statement]\n</code></pre>"},{"location":"reference/bqtools/functions/utilities/","title":"Utilities","text":"<p>These utilities package common actions into simple functions.</p>"},{"location":"reference/bqtools/functions/utilities/#parse-dataset-id","title":"PARSE Dataset ID","text":"Attribute Value Name <code>parse_dataset_id</code> ID <code>bqtools.[region].parse_dataset_id</code> Version <code>bqtools:v1.0.0</code> Description Validates a single <code>dataset_id</code> and parses constituent elements. Type <code>FUNCTION (SQL)</code> Arguments <code>dataset_id STRING</code> Returns <code>STRUCT&lt;dataset_id_input STRING, is_valid BOOL, project_id STRING, dataset_name STRING&gt;</code> Dependencies <code>None</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE dataset_name STRING;\n\nSET dataset_id = 'project_id.dataset_name';\n\nSELECT bqtools.eu.parse_dataset_id(dataset_id);\n</code></pre> <pre><code>DECLARE dataset_name STRING;\n\nSET dataset_id = 'project_id.dataset_name';\n\nSELECT bqtools.us.parse_dataset_id(dataset_id);\n</code></pre>"},{"location":"reference/bqtools/functions/utilities/#parse-resource-id","title":"PARSE Resource ID","text":"Attribute Value Name <code>parse_resource_id</code> ID <code>bqtools.[region].parse_resource_id</code> Version <code>bqtools:v1.0.0</code> Description Validates a single <code>resource_id</code> and parses constituent elements. Type <code>FUNCTION (SQL)</code> Arguments <code>resource_id STRING</code> Returns <code>STRUCT&lt;resource_id_input STRING, is_valid BOOL, project_id STRING, dataset_name STRING, resource_name STRING, dataset_id STRING, resource_id STRING&gt;</code> Dependencies <code>None</code> <p>EXECUTION</p> EUUS <pre><code>DECLARE resource_id STRING;\n\nSET resource_id = 'project_id.dataset_name.resource_name';\n\nSELECT bqtools.eu.parse_resource_id(resource_id);\n</code></pre> <pre><code>DECLARE resource_id STRING;\n\nSET resource_id = 'project_id.dataset_name.resource_name';\n\nSELECT bqtools.us.parse_resource_id(resource_id);\n</code></pre>"},{"location":"reference/decodedata/","title":"Introduction","text":"<p>The Decode Data (<code>decodedata</code>) for GA4 library simplifies and augments the GA4 BigQuery export, making subsequent data operations simpler and quicker. Go to decodedata.io for detailed documentation and registration.</p>"},{"location":"reference/decodedata/#summary","title":"Summary","text":"Attribute Value Name Decode Data Project ID <code>decodedata</code> Version <code>decodedata:v1.0.0</code> Access Licensed Description Enables automatic pre-modelling of the GA4 BigQuery <code>events_YYYYMMDD</code> export, providing flattened, date-partitioned <code>events</code> and <code>sessions</code> tables containing all standard and observed <code>event_params</code> and <code>user_properties</code>. It also provides mechanisms to detect new <code>event_params</code> and <code>user_properties</code> values and to incrementally update the schema based on inbound data detection."},{"location":"reference/decodedata/#deployment","title":"Deployment","text":"<p>Installation and execution functions are currently deployed into the following BigQuery regions, but can be mirrored to additional regions as required:</p> Region Name Dataset ID EU <code>bqtools.eu</code> US <code>bqtools.us</code>"}]}