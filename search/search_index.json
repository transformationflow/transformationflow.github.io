{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#who-we-are","title":"Who we are","text":"<p>Transformationflow O\u00dc is a Google Cloud Partner, headquartered in Estonia (EU). </p> <p>We are a remote, specialist team of Google Cloud Certified Professional Data Engineers who build data automation solutions and libraries on Google Cloud.  We have been working exclusively with Google Cloud and BigQuery since 2017.</p>"},{"location":"#what-we-do","title":"What we do","text":"<p>We design, build, manage and license serverless Google Cloud data automation solutions and libraries.</p>"},{"location":"#how-we-do-it","title":"How we do it","text":"<p>We use BigQuery as a foundation, in addition to complementary Google Cloud products such as:</p> <ul> <li>Google Cloud Storage for file ingestion, storage and backup</li> <li>Pub/Sub for streaming data, messaging and scheduled query monitoring</li> <li>Python Cloud Functions for custom actions, notifications and interaction with external APIs</li> <li>Remote Functions to deploy Cloud Functions in BigQuery workflows</li> <li>Scheduled Queries for automation and orchestration</li> <li>BigQuery ML for AI/ML and generative AI workflows</li> <li>Looker Studio for end-user and data monitoring dashboards</li> </ul> <p>We have advanced capabilities in all aspects of GoogleSQL and the GoogleSQL procedural language.  We use these capabilities to build functions, procedures and table functions which solve complex data automation challenges in a rapid, scalable and replicable manner.</p>"},{"location":"signup/","title":"","text":""},{"location":"signup/#plans","title":"Plans","text":""},{"location":"signup/#installation","title":"Installation","text":""},{"location":"publications/medium/","title":"Medium","text":"<ul> <li> <p> June 21, 2024  11 min read </p> </li> <li> <p> June 14, 2024  17 min read </p> </li> <li> <p> June 5, 2024  16 min read </p> </li> <li> <p> March 27, 2024  5 min read </p> </li> <li> <p> Sep 21, 2023  8 min read </p> </li> <li> <p> May 25, 2022   5 min read </p> </li> <li> <p> Apr 22, 2021   6 min read </p> </li> <li> <p> Aug 5, 2022   9 min read </p> </li> <li> <p> Mar 15, 2022   9 min read </p> </li> <li> <p> Jan 3, 2022   7 min read </p> </li> <li> <p> Nov 10, 2021   4 min read </p> </li> <li> <p> Apr 27, 2021   3 min read </p> </li> </ul>"},{"location":"publications/medium/#understanding-the-ga4-bigquery-export-schema-and-structure","title":"Understanding the GA4 BigQuery Export Schema and Structure","text":""},{"location":"publications/medium/#_1","title":"Medium","text":"<p>A qualitative investigation into one of the weirdest data structures ever forced upon millions of innocent, unsuspecting analysts</p> <p> Continue reading</p>"},{"location":"publications/medium/#a-guide-to-functional-data-engineering-in-bigquery","title":"A Guide to Functional Data Engineering in BigQuery","text":""},{"location":"publications/medium/#_2","title":"Medium","text":"<p>An exploration of the Functional Data Engineering paradigm and how to implement this in BigQuery</p> <p> Continue reading</p>"},{"location":"publications/medium/#how-to-build-a-simple-data-stack-on-bigquery","title":"How to Build a Simple Data Stack on BigQuery","text":""},{"location":"publications/medium/#_3","title":"Medium","text":"<p>Building data infrastructure on BigQuery is a highly capable, escalable, extensible, accessible and future-proof choice for any team or organisation, at any scale</p> <p> Continue reading</p>"},{"location":"publications/medium/#essential-sql-functions-for-ga4-bigquery-export-analysis","title":"Essential SQL Functions for GA4 BigQuery Export Analysis","text":""},{"location":"publications/medium/#_4","title":"Medium","text":"<p>The fundamental functions you\u2019ll need to master if you want to work with the GA4 events data export in BigQuery</p> <p> Continue reading</p>"},{"location":"publications/medium/#google-pubsub-to-bigquery-the-simple-way","title":"Google Pub/Sub to BigQuery the simple way","text":"<p>A hands-on guide to implementing BigQuery Subscriptions in Pub/Sub for simple message and streaming ingestion</p> <p> Continue reading</p>"},{"location":"publications/medium/#getting-started-with-bigquery-sql-user-defined-functions-sql-udfs","title":"Getting Started with BigQuery SQL User Defined Functions (SQL UDFs)","text":"<p>A powerful and fundamental building block which enables custom extension of the core BigQuery platform functionality</p> <p> Continue reading</p>"},{"location":"publications/medium/#google-cloud-storage-gcs-to-bigquery-the-simple-way","title":"Google Cloud Storage (GCS) to BigQuery the simple way","text":"<p>Because simple is better than complex (but complex is better than complicated)</p> <p> Continue reading</p>"},{"location":"publications/medium/#how-to-build-a-unique-md5-row-hash-using-sql-in-bigquery-plus-a-few-related-things","title":"How to Build a Unique MD5 Row Hash Using SQL in BigQuery (Plus a Few Related Things)","text":"<p>Using native BigQuery functionality to generate a dynamic, unique row identifier in SQL</p> <p> Continue reading</p>"},{"location":"publications/medium/#plotting-bar-charts-in-bigquery-using-a-sql-user-defined-function-udf","title":"Plotting Bar Charts in BigQuery Using a SQL User Defined Function (UDF)","text":"<p>Minimise context switching and make your workflow faster</p> <p> Continue reading</p>"},{"location":"publications/medium/#sql-string-templating-in-bigquery-scripts-four-methods","title":"SQL String Templating in BigQuery Scripts: Four Methods","text":"<p>Powerful foundational techniques to help unlock the power of BigQuery scripting and automation</p> <p> Continue reading</p>"},{"location":"publications/medium/#getting-started-with-bigquery-scripting","title":"Getting Started with BigQuery Scripting","text":"<p>Demystifying this powerful but potentially difficult to grasp aspect of BigQuery functionality, one simple step at a time</p> <p> Continue reading</p>"},{"location":"publications/medium/#connecting-bigquery-to-colab-and-converting-query-results-to-python-dictionaries","title":"Connecting BigQuery to Colab and Converting Query Results to Python Dictionaries","text":"<p>A simple method for working with BigQuery results in Python (for pandaphobes)</p> <p> Continue reading</p>"},{"location":"reference/terminology/","title":"Terminology","text":"<p>The following definitions are used consistently across all functions and development activity.  These definitions may override some of the standard Google definitions which can be inconsistent across different system functions, views and user interfaces.</p>"},{"location":"reference/terminology/#resource-types","title":"Resource Types","text":"Resource Type  Description Docs  <code>TABLE</code> The collective terminology for a resource of type <code>BASE TABLE</code>, <code>PARTITIONED TABLE</code>, <code>SHARDED TABLE</code>, <code>EXTERNAL TABLE</code>, <code>SNAPSHOT</code> or <code>VIEW</code> Introduction to tables <code>BASE TABLE</code> A native BigQuery table, for which the data is physically stored within BigQuery Standard BigQuery tables <code>PARTITIONED TABLE</code> A native BigQuery table where the data is stored in physically separate partitions (typically using a <code>DATE</code> column), enabling efficient and performant query execution Partitioned tables <code>DATE-PARTITIONED TABLE (DPT)</code> A partitioned table which is partitioned by a specific date column. Partitioned tables <code>SHARDED TABLE</code> A set of tables with a common schema and prefix, but with distinct suffixes (e.g. <code>[prefix]_YYYYMMDD</code> for date-based sharding) Partitioning versus sharding <code>DATE-SHARDED TABLE (DST)</code> A sharded table which is sharded by date, with table names in the format <code>[prefix]_YYYYMMDD</code> Partitioning versus sharding <code>EXTERNAL TABLE</code> A BigQuery table where the data is stored externally, either within the Google ecosystem (Google Sheets, files on Google Cloud Storage) or externally (Amazon S3, Azure Blob Storage) External tables <code>SNAPSHOT</code> An efficient mechanism for recording point-in-time table contents Introduction to table snapshots <code>VIEW</code> An ephemeral table-like logical resource defined by a SQL query Views <code>ROUTINE</code> The collective terminology for a resource of type <code>FUNCTION</code>, <code>PROCEDURE</code>, <code>TABLE FUNCTION</code> or <code>REMOTE FUNCTION</code> Manage Routines <code>FUNCTION</code> User-defined code (SQL, native Javascript or packaged Javascript libraries) which wraps logic into a reusable and shareable function, taking zero or more type-specific arguments and returning a single value User-defined functions <code>PROCEDURE</code> A set of statements which takes zero or more type-specific arguments and enables complex logic and actions to be packaged into a single, reusable and shareable resource SQL stored procedures <code>TABLE FUNCTION (TF)</code> A parameterized <code>VIEW</code> which can support more complex, optimized query patterns Table functions <code>DATE-BOUNDED TABLE FUNCTION (DBTF)</code> A table function with precisely two <code>DATE</code> parameters as arguments: <code>start_date</code> and <code>end_date</code> Table functions <code>REMOTE FUNCTION</code> A Cloud Function written in one of a variety of languages which can be called like a BigQuery <code>FUNCTION</code>, enabling interaction with external APIs and libraries from BigQuery queries and workflows Work with remote functions <code>SCHEDULED QUERY</code> An arbitrary SQL statement which can be scheduled to run periodically Scheduling Queries"},{"location":"reference/terminology/#naming-conventions","title":"Naming Conventions","text":"Term  Data Type Description <code>project_id</code> <code>STRING</code> The globally unique identifier for each project <code>dataset_name</code> <code>STRING</code> The name for each dataset, unique in each project <code>dataset_id</code> <code>STRING</code> The globally unique identifier for each dataset, composed as <code>project_id.dataset_name</code> <code>resource_name</code> <code>STRING</code> The single name for each resource (<code>TABLE</code>, <code>VIEW</code>, <code>FUNCTION</code>, <code>TABLE FUNCTION</code> or <code>PROCEDURE</code>) <code>resource_id</code> <code>STRING</code> The globally unique identifier for an individual <code>TABLE</code>, <code>VIEW</code>, <code>FUNCTION</code>, <code>TABLE FUNCTION</code> or <code>PROCEDURE</code>, composed as <code>project_id.dataset_name.resource_name</code> <code>date_id</code> <code>STRING</code> A <code>STRING</code> representantion of a date in the format <code>YYYYMMDD</code> <code>shard_id</code> <code>STRING</code> A <code>STRING</code> representantion of a table shard date in the format <code>YYYYMMDD</code> <code>shard_date</code> <code>DATE</code> A <code>DATE</code> representantion of a table shard date <code>partition_id</code> <code>STRING</code> A <code>STRING</code> representantion of a table partition date in the format <code>YYYYMMDD</code> <code>partition_date</code> <code>DATE</code> A <code>DATE</code> representantion of a table partition date"},{"location":"reference/terminology/#language-types","title":"Language Types","text":"Language Type  Description Docs  GoogleSQL An ANSI compliant superset of Structured Query Language (SQL) SQL in BigQuery Procedural Language The core language which enables programmatic execution of arbitrary logic Procedural Language Data Definition Language Statements which enable creation and modification of BigQuery resources DDL Statements Data Manipulation Language Statements which enable insertion, deletion and modification of data DML Statements Data Control Language Statements which enable access control to BigQuery resources DCL Statements"}]}